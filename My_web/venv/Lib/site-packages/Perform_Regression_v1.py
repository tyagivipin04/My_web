import pandas as pd
import numpy as np
from scipy import stats
# from sqlalchemy import create_engine
import json
from sklearn import linear_model
import statsmodels.api as sm

## INPUTS EXPECTED
Forecasting_Macro_Variables = "GDP"
Macro_Variables_For_Regression = ["GDP"]
Pairs_For_Multilinear_Regression = []
NumberOfYears_EAD = 8  # Client manual INput
EIR = 12.44  # (%)
LGD = 17  # (%)
Probability_Weights = [68.27, 0, 31.73]  # for Base, Best and Worst Case, respectively

################ HARDCODES: NEEDS ATTENTION ###############
Active_DPD_Buckets = ["CURRENT", "(1 - 30)", "(31 - 60)", "(61 - 90)"]
EAD_DPD_Buckets = ['Current', '(1 - 30)', '(31 - 60)', '(61 - 90)', '90+']
Years_Avg_PD = ["2018", "2019",
                "2020"]  # These are used for calculating avg PD. This will mostly come ready from some Redshift table

# Paths of Static Files
ConfigJSONFilePath = ""
TableDetailsJSONFilePath = ""


# This function establishes a connection with the database (Redshift as of now)
def Connect_To_Database():
    global engine, Connection

    # Reading Config JSON file
    with open(ConfigJSONFilePath, 'r') as file:
        ConfigDetails = json.loads(file.read())

    UserName = ConfigDetails["UserName"]
    Password = ConfigDetails["Password"]
    HostName = ConfigDetails["HostName"]
    Port = ConfigDetails["Port"]
    Database = ConfigDetails["Database"]

    # Establishing the connection
    ConnectionPath = 'postgresql://' + UserName + ':' + Password + '@' + HostName + ':' + str(Port) + '/' + Database
    engine = create_engine(ConnectionPath)
    Connection = engine.connect()


# This function runs a select query on the database (Redshift as of now). This is to read input data from the Client.
def Query_Database(TableName):
    Query = TableDetails[TableName]["SelectQuery"]

    if "REPORTING_DATE" in Query:
        Query = Query.replace("REPORTING_DATE", Reporting_Date)
    if "LINE_OF_BUSINESS" in Query:
        Query = Query.replace("LINE_OF_BUSINESS", LoB)


    df = pd.read_sql(Query, engine)
    return df


# This function reads the JSON file for Table wise query details and calls the Query_Database function
def Read_Tables_From_Database():
    global TableDetails
    global DPD_Bucket_Details_df, Macro_Economic_Multipliers_df, Macro_Economic_Variables_df, PD_Agg_Data_df

    Tables = ["DPD_Bucket_Details", "Macro_Economic_Multipliers", "Macro_Economic_Variables", "PD_Agg_Data"]

    # Reading the table details from JSON file
    with open(TableDetailsJSONFilePath, 'r') as file:
        TableDetails = json.loads(file.read())

    DPD_Bucket_Details_df = Query_Database("DPD_Bucket_Details")
    Macro_Economic_Multipliers_df = Query_Database("Macro_Economic_Multipliers")
    Macro_Economic_Variables_df = Query_Database("Macro_Economic_Variables")
    PD_Agg_Data_df = Query_Database("PD_Agg_Data")


def Write_To_Database(TableName):
    Transaction = Connection.begin()

    UpdateQuery = TableDetails[TableName]["UpdateQuery"]
    Connection.execute(UpdateQuery)
    Transaction.commit()


# This function generates forecasted macreconomic variables for best and worst cases, based on the
# base case variables and multipliers input by the client.
def Generate_Macro_Variables_Variation():
    Macro_Variables_BestCase_df = pd.DataFrame(columns=Macro_Variables_Base_df.columns.tolist())
    Macro_Variables_BestCase_df["Year"] = Macro_Variables_Base_df["Year"]

    Macro_Variables_WorstCase_df = pd.DataFrame(columns=Macro_Variables_Base_df.columns.tolist())
    Macro_Variables_WorstCase_df["Year"] = Macro_Variables_Base_df["Year"]

    for column in Macro_Variables_Base_df.iloc[:, 1:]:
        for index_row in range(0, len(Macro_Variables_Base_df)):
            BaseValue = Macro_Variables_Base_df.iat[index_row, Macro_Variables_Base_df.columns.get_loc(column)]
            Multiplier_BestCase = Macro_Multipliers_df.loc[column, "Best Case"]
            Multiplier_WorstCase = Macro_Multipliers_df.loc[column, "Worst case"]
            if BaseValue > 0:
                Macro_Variables_BestCase_df.iat[
                    index_row, Macro_Variables_BestCase_df.columns.get_loc(column)] = BaseValue * Multiplier_BestCase
                Macro_Variables_WorstCase_df.iat[
                    index_row, Macro_Variables_WorstCase_df.columns.get_loc(column)] = BaseValue * Multiplier_WorstCase
            else:
                Macro_Variables_BestCase_df.iat[
                    index_row, Macro_Variables_BestCase_df.columns.get_loc(column)] = BaseValue / Multiplier_BestCase
                Macro_Variables_WorstCase_df.iat[
                    index_row, Macro_Variables_WorstCase_df.columns.get_loc(column)] = BaseValue / Multiplier_WorstCase

    return Macro_Variables_BestCase_df, Macro_Variables_WorstCase_df


def Read_Input_Data(TableName):
    if TableName == "PD_Base_Data":
        df = pd.read_excel("C:/Users/Administrator/Documents/pythoncode/ECL_Testing/ECLWorkbook.xlsx",
                           sheet_name="PD_BaseData", usecols="B:T", skiprows=1)

    elif TableName == "Base_Macro_Variables":
        df = pd.read_excel("C:/Users/Administrator/Documents/pythoncode/ECL_Testing/ECLWorkbook.xlsx",
                           sheet_name="Macro_Data", usecols="B:F", skiprows=2, nrows=13)

    elif TableName == "DPD_Bucket_Details":
        df = pd.read_excel("C:/Users/Administrator/Documents/pythoncode/ECL_Testing/ECLWorkbook.xlsx",
                           sheet_name="Manual_Input_Data", usecols="B:C", skiprows=1)

    elif TableName == "Macro_Multipliers":
        df = pd.read_excel("C:/Users/Administrator/Documents/pythoncode/ECL_Testing/ECLWorkbook.xlsx",
                           sheet_name="Manual_Input_Data", usecols="E:G", skiprows=1, nrows=4)


    else:
        print("Unidentified input table")
        raise Exception

    return df


def Generate_Loan_Ageing_Table():
    global Loan_Ageing_df

    Loan_Ageing_df = DPD_Details_df[["DPD Bucket"]]
    Loan_Ageing_df = Loan_Ageing_df.rename(columns={"DPD Bucket": "Loan Ageing"})

    for month in AllMonths.unique():
        Loan_Ageing_df[month] = ""
        # print(Loan_Ageing_df.shape[1])

    for index_row in range(0, len(Loan_Ageing_df)):
        for column in Loan_Ageing_df.columns:
            if column != "Loan Ageing":
                DPD = Loan_Ageing_df["Loan Ageing"].values[index_row]
                POSValue = PD_BaseData_df.loc[(PD_BaseData_df['Mon_Year'] == str(column)) & (
                            PD_BaseData_df['DPD'] == str(DPD)), 'POS (INR Crs)'].sum()
                Loan_Ageing_df.iat[index_row, Loan_Ageing_df.columns.get_loc(column)] = POSValue

    # print(Loan_Ageing_df.head(5))
    # Loan_Ageing_df.to_csv("C:/Users/Administrator/Documents/pythoncode/ECL_Testing/ECL_PoC/Loan_Ageing.csv", index=False)

    # Write_To_Database("Loan_Ageing")


def Generate_Avg_Loan_Ageing_Table():
    global Avg_Loan_Ageing_df

    Avg_Loan_Ageing_df = pd.DataFrame(columns=AllMonths.unique())
    Avg_Loan_Ageing_df.insert(loc=0, column='Average Loan ageing', value=DPD_List_Full)

    for index_row in range(0, len(Avg_Loan_Ageing_df)):
        for index_column in range(1, Avg_Loan_Ageing_df.shape[1]):
            Avg_Loan_Ageing_df.iat[index_row, index_column] = (Loan_Ageing_df.iloc[index_row:index_row + 1,
                                                               max(1, index_column - 5):index_column + 1].sum(
                axis=1).values[0]) / min(index_column, 6)

    # print(Avg_Loan_Ageing_df.head(5))
    # Avg_Loan_Ageing_df.to_csv("C:/Users/Administrator/Documents/pythoncode/ECL_Testing/ECL_PoC/Avg_Loan_Ageing.csv", index=False)

    # Write_To_Database("Avg_Loan_Ageing")


def Generate_Flow_Rate_Matrix_df():
    global Flow_Rate_Matrix_df

    Flow_Rate_Matrix_df = pd.DataFrame(columns=AllMonths.unique())
    Flow_Rate_Matrix_df.insert(loc=0, column='Flow rate matrix', value=DPD_List_Full)

    for index_row in range(1, len(DPD_List_Full)):
        for index_column in range(2, Flow_Rate_Matrix_df.shape[1]):
            try:
                FlowRate = (min((float(Avg_Loan_Ageing_df.iloc[index_row, index_column]) / float(
                    Avg_Loan_Ageing_df.iloc[index_row - 1, index_column - 1])), 1)) * 100
            except ZeroDivisionError:
                FlowRate = 0
            Flow_Rate_Matrix_df.iat[index_row, index_column] = FlowRate
    Flow_Rate_Matrix_df = Flow_Rate_Matrix_df.fillna("")

    # Flow_Rate_Matrix_df.to_csv("C:/Users/Administrator/Documents/pythoncode/ECL_Testing/ECL_PoC/Flow_Rate_Matrix.csv",index=False)

    # Write_To_Database("Flow_Rate_Matrix")


def Generate_Avg_Flow_Rates_df():  #################### LOGIC TO BE WRITTEN ####################

    global Avg_Flow_Rates_df

    Avg_Flow_Rates_df = pd.read_excel("C:/Users/Administrator/Documents/pythoncode/ECL_Testing/ECLWorkbook.xlsx",
                                      sheet_name="Flow_Rates", usecols="B:E", skiprows=1, nrows=5)
    Avg_Flow_Rates_df = Avg_Flow_Rates_df.fillna("")
    # print(Avg_Flow_Rates_df)

    # Write_To_Database("Avg_Flow_Rates")


def Generate_Avg_PDs_df():
    global Avg_PDs_df

    # Avg_PDs_df = pd.read_excel("C:/Users/Administrator/Documents/pythoncode/ECL_Testing/ECLWorkbook.xlsx",sheet_name="Flow_Rates", usecols="B:F", skiprows=8, nrows=5)

    Avg_PDs_df = pd.DataFrame(columns=Avg_Flow_Rates_df.iloc[:, 1:].columns.tolist())
    Avg_PDs_df.insert(loc=0, column='Average PDs', value=Active_DPD_Buckets)
    Avg_PDs_df["TTC PD"] = ""

    for index_row in range(0, len(Avg_PDs_df)):
        Total_TTC = 0
        for index_column in range(1, Avg_PDs_df.shape[1] - 1):
            PD_Year = round(
                Avg_Flow_Rates_df.iloc[index_row + 1:, index_column:index_column + 1].product(axis=0).values[0] * 100,
                2)
            Avg_PDs_df.iat[index_row, index_column] = PD_Year
            Total_TTC += PD_Year
        Avg_PDs_df.iat[index_row, Avg_PDs_df.columns.get_loc("TTC PD")] = round(Total_TTC / index_column, 2)

    # print(Avg_PDs_df)

    # Write_To_Database("Avg_PDs")


def Generate_Count_Of_Borrowers_df():
    global Count_Of_Borrowers_df

    Count_Of_Borrowers_df = pd.read_excel("C:/Users/Administrator/Documents/pythoncode/ECL_Testing/ECLWorkbook.xlsx",
                                          sheet_name="Flow_Rates", usecols="B:E", skiprows=17, nrows=4)
    # print(Count_Of_Borrowers_df)


def Generate_Hist_PD_Rates_df():
    global Hist_PD_Rates_df, Avg_Current_WAPD

    Hist_PD_Rates_df = pd.DataFrame(columns=Years_Avg_PD, index=None)
    Hist_PD_Rates_df.insert(loc=0, column='Metric',
                            value=["Historical portfolio default rates", "Historical portfolio default rates - LN"])

    for index_column in range(1, Hist_PD_Rates_df.shape[1]):
        Avg_PDs_list = Avg_PDs_df.iloc[:4, :].iloc[:, index_column].tolist()  # For the given year
        Count_Of_Borrowers_list = Count_Of_Borrowers_df.iloc[:, index_column].tolist()  # For the given year
        Hist_PD_Rate = (np.dot(Avg_PDs_list, Count_Of_Borrowers_list)) / (
        Count_Of_Borrowers_df.iloc[:, index_column:index_column + 1].sum(axis=0).values[0])
        Hist_PD_Rates_df.iat[0, index_column] = Hist_PD_Rate
        NormalizedValue = (max(Hist_PD_Rate / 100, 0.00005) / (1 - max(Hist_PD_Rate / 100, 0.00005)))
        Hist_PD_Rate_LN = np.log(NormalizedValue)
        Hist_PD_Rates_df.iat[1, index_column] = Hist_PD_Rate_LN

    Avg_Current_WAPD = Hist_PD_Rates_df.iloc[0:1, 1:].mean(axis=1).values[0]
    # print(Hist_PD_Rates_df)


def ForecastUsingRegression(MacroVariable):
    global Regression_Forecast_BaseCase_df, Regression_Forecast_BestCase_df, Regression_Forecast_WorstCase_df

    # Forecasting for base case
    InputForForecasting = \
    Macro_Variables_Base_df[Macro_Variables_Base_df.Year.isin(list(map(int, Years_Forecasting)))].reset_index()[
        [MacroVariable]]
    Regression_Forecast_BaseCase_df[MacroVariable] = InputForForecasting * Variable1 + Intercept

    # Forecasting for best case
    InputForForecasting = \
    Macro_Variables_BestCase_df[Macro_Variables_BestCase_df.Year.isin(list(map(int, Years_Forecasting)))].reset_index()[
        [MacroVariable]]
    Regression_Forecast_BestCase_df[MacroVariable] = InputForForecasting * Variable1 + Intercept

    # Forecasting for worst case
    InputForForecasting = Macro_Variables_WorstCase_df[
        Macro_Variables_WorstCase_df.Year.isin(list(map(int, Years_Forecasting)))].reset_index()[[MacroVariable]]
    Regression_Forecast_WorstCase_df[MacroVariable] = InputForForecasting * Variable1 + Intercept


def Perform_Regression():

    global Regression_Base_Current_Data_df, Regression_Results_df, Hist_PD_Table_df
    global Regression_Forecast_BaseCase_df, Regression_Forecast_BestCase_df, Regression_Forecast_WorstCase_df
    global RegModel, Intercept, Variable1, Variable2

    Regression_Results_df = pd.DataFrame(columns=list(set(Macro_Variables_List + Pairs_For_Multilinear_Regression)))
    Regression_Results_df.insert(loc=0, column='Parameter',
                                 value=["Intercept", "Variable1", "Variable2", "Multiple R", "R Squared",
                                        "Adjusted R squared", "p-Values"])

    Hist_PD_Table_df = pd.DataFrame(columns=Macro_Variables_List)
    Hist_PD_Table_df.insert(loc=0, column='Year', value=Years_Avg_PD)
    Hist_PD_Table_df.insert(loc=1, column='Historical portfolio default rates - LN', value=Hist_PD_Rates_df.iloc[1:2,1:].values[0])


    Macro_Variables_Base_df.set_index("Year", inplace=True)


    for index_row in range(len(Hist_PD_Table_df)):
        Year = int(Hist_PD_Table_df["Year"].values[index_row])
        for MEV in Macro_Variables_List:
            Hist_PD_Table_df.iat[index_row, Hist_PD_Table_df.columns.get_loc(MEV)] = Macro_Variables_Base_df.loc[Year,MEV]

    Macro_Variables_Base_df.reset_index(inplace=True)
    # Hist_PD_Table_df.reset_index(inplace=True)
    # print(Hist_PD_Table_df)



    Regression_Forecast_BaseCase_df = pd.DataFrame(
        columns=list(set(Macro_Variables_List + Pairs_For_Multilinear_Regression)))
    Regression_Forecast_BaseCase_df.insert(loc=0, column='Year', value=Years_Forecasting)

    Regression_Forecast_BestCase_df = Regression_Forecast_BaseCase_df.copy()
    Regression_Forecast_WorstCase_df = Regression_Forecast_BaseCase_df.copy()

    Regression_Results_df.set_index("Parameter", inplace=True)

    for column in Regression_Results_df.columns.tolist():
        if column != "Parameter":
            if "+" in column:  # Multiple variables, case of multilinear regression
                RegressionType = "MultiLinear"
                MacroVariable_1 = column.split("+")[0].strip()
                MacroVariable_2 = column.split("+")[1].strip()
                X = Macro_Variables_Base_df[Macro_Variables_Base_df.Year.isin(list(map(int, Years_Avg_PD)))][
                    [MacroVariable_1, MacroVariable_2]].reset_index()

            else:  # Simple linear regression
                RegressionType = "SimpleLinear"
                MacroVariable_1 = column.strip()
                X = \
                Macro_Variables_Base_df[Macro_Variables_Base_df.Year.isin(list(map(int, Years_Avg_PD)))].reset_index()[
                    [MacroVariable_1]]

            Hist_PD_Rates_list = [Hist_PD_Rates_df.iat[1, x] for x in range(1, Hist_PD_Rates_df.shape[1])]
            Hist_PD_Rates_temp_df = pd.DataFrame(index=None)
            Hist_PD_Rates_temp_df.insert(loc=0, column='Hist_PD_Rates', value=Hist_PD_Rates_list)

            Y = Hist_PD_Rates_temp_df["Hist_PD_Rates"]

            X = sm.add_constant(X)
            RegModel = sm.OLS(Y, X).fit()

            # print(RegModel.summary())

            P_Values_df = pd.DataFrame(RegModel.pvalues, columns=["p-value"], index=None)
            ModelParams_df = pd.DataFrame(RegModel.params, columns=["value"], index=None)

            if RegressionType == "SimpleLinear":
                Variable1 = ModelParams_df.loc[MacroVariable_1, "value"]
                Variable2 = 0
            elif RegressionType == "MultiLinear":
                Variable1 = ModelParams_df.loc[MacroVariable_1, "value"]
                Variable2 = ModelParams_df.loc[MacroVariable_2, "value"]

            Intercept = ModelParams_df.loc["const", "value"]

            # Writing values to the regression results table
            Regression_Results_df.loc["Intercept", column] = Intercept
            Regression_Results_df.loc["Variable1", column] = Variable1
            Regression_Results_df.loc["Variable2", column] = Variable2
            Regression_Results_df.loc["Multiple R", column] = pow(RegModel.rsquared, 0.5)
            Regression_Results_df.loc["R Squared", column] = RegModel.rsquared
            Regression_Results_df.loc["Adjusted R squared", column] = RegModel.rsquared_adj
            Regression_Results_df.loc["p-Values", column] = P_Values_df.loc[column, "p-value"]

            ForecastUsingRegression(column)  # column:Macrovariable

    # Hist_PD_Table_df.reset_index(inplace=True)
    Regression_Results_df.reset_index(inplace=True)

    Hist_PD_Table_JSON = Hist_PD_Table_df.to_json(orient="records")
    Regression_Results_JSON = Regression_Results_df.to_json(orient="records")

    # print(Hist_PD_Table_df)
    # print(Regression_Results_df)
    # print(Hist_PD_Table_JSON)
    # print(Regression_Results_JSON)

    # Hist_PD_Table_df.to_csv("C:/Users/Administrator/Documents/pythoncode/ECL_Testing/Hist_PD_Table.csv")
    # Regression_Results_df.to_csv("C:/Users/Administrator/Documents/pythoncode/ECL_Testing/ECLRegressionOutput.csv")

    # Keeping all the fields as float, and converting the Year field back to int
    Regression_Forecast_BaseCase_df = Regression_Forecast_BaseCase_df.astype("float")
    Regression_Forecast_BaseCase_df = Regression_Forecast_BaseCase_df.astype({"Year": "int"})

    # Keeping all the fields as float, and converting the Year field back to int
    Regression_Forecast_BestCase_df = Regression_Forecast_BestCase_df.astype("float")
    Regression_Forecast_BestCase_df = Regression_Forecast_BestCase_df.astype({"Year": "int"})

    # Keeping all the fields as float, and converting the Year field back to int
    Regression_Forecast_WorstCase_df = Regression_Forecast_WorstCase_df.astype("float")
    Regression_Forecast_WorstCase_df = Regression_Forecast_WorstCase_df.astype({"Year": "int"})



def Save_Outputs():
    
    # C:/Users/Administrator/Documents/pythoncode/ECL_Testing
    
    Regression_Results_df.to_csv("C:/Users/Administrator/Documents/pythoncode/ECL_Testing/Regression_Results.csv")
    Hist_PD_Table_df.to_csv("C:/Users/Administrator/Documents/pythoncode/ECL_Testing/Hist_PD_Table.csv")
    Regression_Forecast_BaseCase_df.to_csv("C:/Users/Administrator/Documents/pythoncode/ECL_Testing/Regression_Forecast_BaseCase.csv")
    Regression_Forecast_BestCase_df.to_csv("C:/Users/Administrator/Documents/pythoncode/ECL_Testing/Regression_Forecast_BestCase.csv")

    Regression_Forecast_WorstCase_df.to_csv("C:/Users/Administrator/Documents/pythoncode/ECL_Testing/Regression_Forecast_WorstCase.csv")

    
    

def main(LineOfBusiness, ReportDate):

    global PD_BaseData_df, AllMonths  # PD Base Data
    global DPD_Details_df, DPD_List_Full, Macro_Multipliers_df  # Manual Input Data
    global Macro_Variables_List, Macro_Variables_Base_df, Macro_Variables_BestCase_df, Macro_Variables_WorstCase_df, Years_Forecasting  # Macroeconomic variables
    global ECL_On_Book_BaseCase_df, ECL_On_Book_BestCase_df, ECL_On_Book_WorstCase_df  # ECL on book
    global Reporting_Date, LoB          #Filter Parameters

    # Connect_To_Database()

    Reporting_Date = ReportDate
    LoB = LineOfBusiness, ReportDate
    
    """---------------------------------------------READING INPUTS----------------------------------------"""

    #[Sheet : 'PD_BaseData']
    PD_BaseData_df = Read_Input_Data("PD_Base_Data")
    PD_BaseData_df['Mon_Year'] = PD_BaseData_df['Month'].dt.strftime('%b-%Y')
    AllMonths = PD_BaseData_df.Mon_Year

    #[Sheet: 'Manual_Input_Data']
    DPD_Details_df = Read_Input_Data("DPD_Bucket_Details")
    DPD_List_Full = DPD_Details_df["DPD Bucket"].tolist()
    Macro_Multipliers_df = Read_Input_Data("Macro_Multipliers")
    Macro_Multipliers_df.set_index("Macro economic variable", inplace=True)

    #[Sheet : 'Macro_Data']
    Macro_Variables_Base_df = Read_Input_Data("Base_Macro_Variables")
    Macro_Variables_Base_df = Macro_Variables_Base_df.rename(columns={"Unnamed: 1": "Year"})
    Macro_Variables_Base_df.astype({'Year': 'int32'})
    Macro_Variables_List = Macro_Variables_Base_df.columns.tolist()
    Macro_Variables_List.remove("Year")

    Years_Forecasting = []
    MaxYearAvgPD = Years_Avg_PD[-1]
    for year in Macro_Variables_Base_df["Year"].tolist():
        if int(year) > int(MaxYearAvgPD):
            Years_Forecasting.append(year)

    Macro_Variables_BestCase_df, Macro_Variables_WorstCase_df = Generate_Macro_Variables_Variation()

    """----------------------------------COMPUTING CASH FLOW AGEING & FLOW RATE MATRIX----------------------------"""
    Generate_Loan_Ageing_Table()
    Generate_Avg_Loan_Ageing_Table()
    Generate_Flow_Rate_Matrix_df()
    Generate_Avg_Flow_Rates_df()
    Generate_Avg_PDs_df()
    Generate_Count_Of_Borrowers_df()
    Generate_Hist_PD_Rates_df()

    """---------------------------------------------PERFORMING REGRESSION----------------------------------------"""
    Perform_Regression()


    #Saving output files to be used by the ECL calculation scripts
    Save_Outputs()

    # Closing the database connection
    # Connection.close()



# if __name__ == "__main__":
    # main()
